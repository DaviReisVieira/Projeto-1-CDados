{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 1 - Ciência dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: Breno Quessie Barbosa de Lima\n",
    "\n",
    "Nome: Davi Reis Vieira de Souza"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Atenção:** Serão permitidos grupos de três pessoas, mas com uma rubrica mais exigente. Grupos deste tamanho precisarão fazer um questionário de avaliação de trabalho em equipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Carregando algumas bibliotecas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Em `filename`, coloque o nome do seu arquivo de dados!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "filename = 'skybrasil.xlsx'\n",
    "if filename in os.listdir():\n",
    "    print(f'Encontrei o arquivo {filename}, tudo certo para prosseguir com o Projeto!')\n",
    "else:\n",
    "    print(f'Não encontrei o arquivo {filename} aqui no diretório {os.getcwd()}, será que você não baixou o arquivo?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando a base de dados com os tweets classificados como relevantes e não relevantes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_excel(filename)\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_excel(filename, sheet_name = 'Teste')\n",
    "test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Classificação'] = train['Classificação'].astype('category')\n",
    "train['Classificação'].cat.categories = ('Irrelevante','Neutro','Relevante')\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Classificação'] = test['Classificação'].astype('category')\n",
    "test['Classificação'].cat.categories = ('Irrelevante','Neutro','Relevante')\n",
    "test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_value_counts = train['Classificação'].value_counts()\n",
    "print('-----------Dataframe de Treinamento------------')\n",
    "print('Relevante:', train_value_counts[2])\n",
    "print('Neutro:', train_value_counts[1])\n",
    "print('Irrelevante:', train_value_counts[0])\n",
    "print('-----------------------------------------------')\n",
    "\n",
    "train_value_counts.plot(kind='bar', title='Dataframe de Treinamento',color = ['g', 'y','r']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_value_counts = test['Classificação'].value_counts()\n",
    "print('--------------Dataframe de Teste---------------')\n",
    "print('Relevante:', test_value_counts[2])\n",
    "print('Neutro:', test_value_counts[1])\n",
    "print('Irrelevante:', test_value_counts[0])\n",
    "print('-----------------------------------------------')\n",
    "\n",
    "test_value_counts.plot(kind='bar', title='Dataframe de Teste',color = ['g', 'y','r']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classificador automático de sentimento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faça aqui uma descrição do seu produto e o que considerou como relevante ou não relevante na classificação dos tweets.\n",
    "\n",
    "Produto escolhido: Sky Brasil, uma empresa concessionária de serviços de telecomunicações brasileira. Trabalha com televisão por assinatura via satélite e internet banda larga 4G.\n",
    "\n",
    "Consideramos relevante os tweets que possuem reclamações ou elogios pertinentes para a empresa, os quais podem agregar com feedbacks para melhorar a qualidade do serviço, atendimento ou na resolução de problemas técnicos. É classificado como neutro os tweets que possuem alguma citação direta com o produto, mas não agregam para o melhoramento. A classificação como irrelevante diz respeito aos tweets que são citações incompletas, as quais não fazem sentido, ou propagandas do próprio produto sobre os seus serviços, ou seja, conteúdo que não tem valor para melhorar a Sky."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Montando um Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$P(C|frase) = \\frac{P(frase|C) P(C)}{P(frase)}$\n",
    "\n",
    "$Frase$ = Esse é apenas um exemplo da equação\n",
    "\n",
    "$P(frase|C) = P(Esse|C).P(é|C).P(apenas|C).P(um|C).P(exemplo|C).P(da|C).P(equação|C)$\n",
    "\n",
    "\n",
    "Laplace Smoothing:\n",
    "$P(W) = \\frac{W_{count} + k}{total_{count} + k * |classificação|}$\n",
    "\n",
    "$P(C|frase) = P(Esse) * P(é) * P(apenas) *...*P(C)$\n",
    "\n",
    "\n",
    "$\\log P(C)+ \\log P(Esse|C)+ \\log P(é|C)+...+\\log P(equação|C)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Why do we need Laplace smoothing in Naive Bayes while logarithm may resolve the problem?](https://stats.stackexchange.com/questions/274251/why-do-we-need-laplace-smoothing-in-naive-bayes-while-logarithm-may-resolve-the)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funções de limpeza e tratamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "\n",
    "def cleanup(frase_suja):\n",
    "    frase_limpa = re.sub(r'http\\S+', '', frase_suja, flags=re.MULTILINE) #Removendo Links no Tweet\n",
    "    frase_limpa = \" \".join(re.findall(\"(\\w+|[^\\w ]+)\",frase_limpa)) #Adiciona espaços entre os emojis\n",
    "    frase_limpa = re.sub('\\s*([@])\\s*', r' \\1', frase_limpa) #Juntando @ anteriormente separados\n",
    "    frase_limpa = re.sub(re.compile('[!-.:?;]'), '', frase_limpa) #Removendo pontuações e sinais\n",
    "    frase_limpa=re.sub('(\\s+)',' ',frase_limpa) #Removendo multiplos espaços\n",
    "    frase_limpa=frase_limpa.lower() #Deixando todas as letras em minúsculo\n",
    "    \n",
    "    return frase_limpa "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Montando o Classificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayesModel:\n",
    "    \n",
    "    def __init__(self,classifications_list):\n",
    "        \n",
    "        self.classifications=np.unique(classifications_list)\n",
    "        \n",
    "\n",
    "    def dictIncrement(self,str_array,dict_index):\n",
    "        str_array=str_array[0]\n",
    "            \n",
    "        for single_word in str_array.split():      \n",
    "            self.classifications_dicts[dict_index][single_word]+= 1 \n",
    "            \n",
    "    def fit(self,dataset,labels):    \n",
    "        self.training_strs=dataset\n",
    "        self.labels=labels\n",
    "        self.classifications_dicts=np.array([defaultdict(lambda: 0) for i in range(self.classifications.shape[0])])\n",
    "                        \n",
    "        if not isinstance(self.training_strs,np.ndarray): \n",
    "            self.training_strs=np.array(self.training_strs)\n",
    "            \n",
    "        if not isinstance(self.labels,np.ndarray): \n",
    "            self.labels=np.array(self.labels)\n",
    "            \n",
    "        for classification_index,classification in enumerate(self.classifications):\n",
    "            unique_class_array=self.training_strs[self.labels==classification]            \n",
    "            unique_class_array_cleaned=[cleanup(i) for i in unique_class_array]            \n",
    "            unique_class_array_cleaned=pd.DataFrame(data=unique_class_array_cleaned)\n",
    "            \n",
    "            np.apply_along_axis(self.dictIncrement,1,unique_class_array_cleaned,classification_index)\n",
    "            \n",
    "          \n",
    "        #P(W)=(Count(W|C)+1)/[Count(C)+V])*P(C)\n",
    "        \n",
    "        classification_prob=np.empty(self.classifications.shape[0]) # P(C)\n",
    "        all_words=[]\n",
    "        clas_word_counts=np.empty(self.classifications.shape[0])\n",
    "        for classification_index,classification in enumerate(self.classifications):           \n",
    "            classification_prob[classification_index]=np.sum(self.labels==classification)/float(self.labels.shape[0]) # P(C)\n",
    "            \n",
    "            # nº Palavras/classificação\n",
    "            clas_word_counts[classification_index]=np.sum(np.array(list(self.classifications_dicts[classification_index].values())))+1 # |v| is remaining to be added\n",
    "            # Palavras/Classificação                          \n",
    "            all_words+=self.classifications_dicts[classification_index].keys() \n",
    "                                                     \n",
    "        \n",
    "        #Vocabulary        \n",
    "        self.vocaburary=np.unique(np.array(all_words))\n",
    "        self.vocaburary_size=self.vocaburary.shape[0]\n",
    "        \n",
    "        #computing denominator value                                      \n",
    "        denominator=np.array([clas_word_counts[classification_index]+self.vocaburary_size for classification_index,classification in enumerate(self.classifications)])\n",
    "\n",
    "        #[Dict with words({word:word_count}),Classification probability, denominator value]\n",
    "        self.category_array=[(self.classifications_dicts[classification_index],classification_prob[classification_index],denominator[classification_index]) for classification_index,classification in enumerate(self.classifications)]                               \n",
    "        self.category_array=np.array(self.category_array)\n",
    "        \n",
    "    def predictStrForEachClassification(self,phrase):                                                                                                                \n",
    "        words_prop=np.zeros(self.classifications.shape[0]) #to store probability for each class\n",
    "        \n",
    "        #finding probability for each class of the given test example\n",
    "        for classification_index,classification in enumerate(self.classifications): \n",
    "            phrase=cleanup(phrase)\n",
    "            for test_token in phrase.split(): #split the test example and get p of each test word                            \n",
    "                \n",
    "                #Numerator                         \n",
    "                test_token_counts=self.category_array[classification_index][0].get(test_token,0)+1\n",
    "                \n",
    "                #Probability for this Word                            \n",
    "                word_prob=test_token_counts/float(self.category_array[classification_index][2])  \n",
    "                \n",
    "                #We are using Log to prevent negative values and optimize process\n",
    "                words_prop[classification_index]+=np.log(word_prob)\n",
    "                                              \n",
    "        #P(W)=(Count(W|C)+1)/[Count(C)+V])*P(C) \n",
    "        phrase_prop=np.empty(self.classifications.shape[0])\n",
    "        for classification_index,classification in enumerate(self.classifications):\n",
    "            phrase_prop[classification_index]=words_prop[classification_index]+np.log(self.category_array[classification_index][1])                                  \n",
    "      \n",
    "        return phrase_prop\n",
    "   \n",
    "    def predict(self,test_set): \n",
    "        predictions=[] \n",
    "        for test_str in test_set:                                               \n",
    "            phrase_prop=self.predictStrForEachClassification(test_str) \n",
    "            predictions.append(self.classifications[np.argmax(phrase_prop)])\n",
    "        return np.array(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verificando a performance do Classificador\n",
    "\n",
    "Agora você deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=train['Treinamento']\n",
    "train_labels=train['Classificação']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb=NaiveBayesModel(train_labels)\n",
    "\n",
    "print (\"Treinando o Modelo...\")\n",
    " \n",
    "nb.fit(train_data,train_labels)\n",
    "\n",
    "print ('\\nTreino Completo!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels=test['Classificação']\n",
    "test_data=test['Teste']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "novas_classificacoes = nb.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Previsão']=novas_classificacoes\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concluindo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acurancia=np.sum(test['Previsão']==test_labels)/test_labels.shape[0]\n",
    "\n",
    "print (\"Acurância do Modelo: \",acurancia*100,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def plot_confusion_matrix(cm, target_names, title='Matriz de Confusão', cmap=None, normalize=True):\n",
    "    accuracy = np.trace(cm) / float(np.sum(cm))\n",
    "    misclass = 1 - accuracy\n",
    "    if cmap is None:\n",
    "        cmap = plt.get_cmap('Blues')\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    if target_names is not None:\n",
    "        tick_marks = np.arange(len(target_names))\n",
    "        plt.xticks(tick_marks, target_names, rotation=45)\n",
    "        plt.yticks(tick_marks, target_names)\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        if normalize:\n",
    "            plt.text(j, i, \"{:0.2f}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        else:\n",
    "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('Classificação Verdadeira')\n",
    "    plt.xlabel('Previsão\\nAcurácia={:0.4f}; Classificação Incorreta={:0.4f}'.format(accuracy, misclass))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(confusion_matrix(test['Classificação'], test['Previsão']), ['Irrelevante', 'Neutro','Relevante'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtro_I = test_labels=='Irrelevante'\n",
    "filtro_I_verdadeiro = (test_labels=='Irrelevante')&(test['Previsão']=='Irrelevante')\n",
    "porcentagem_I_verdadeiro = (test.loc[filtro_I_verdadeiro].shape[0]/test.loc[filtro_I].shape[0])\n",
    "porcentagem_I_falso=1-porcentagem_I_verdadeiro\n",
    "\n",
    "print('Porcentagem de Irrelevantes Verdadeiros: ',porcentagem_I_verdadeiro*100, \"%\")\n",
    "print('Porcentagem de Irrelevantes Falsos: ', porcentagem_I_falso*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtro_N = test_labels=='Neutro'\n",
    "filtro_N_verdadeiro = (test_labels=='Neutro')&(test['Previsão']=='Neutro')\n",
    "porcentagem_N_verdadeiro = (test.loc[filtro_N_verdadeiro].shape[0]/test.loc[filtro_N].shape[0])\n",
    "porcentagem_N_falso=1-porcentagem_N_verdadeiro\n",
    "\n",
    "print('Porcentagem de Neutros Verdadeiros: ',porcentagem_N_verdadeiro*100, \"%\")\n",
    "print('Porcentagem de Neutros Falsos: ', porcentagem_N_falso*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtro_R = test_labels=='Relevante'\n",
    "filtro_R_verdadeiro = (test_labels=='Relevante')&(test['Previsão']=='Relevante')\n",
    "porcentagem_R_verdadeiro = (test.loc[filtro_R_verdadeiro].shape[0]/test.loc[filtro_R].shape[0])\n",
    "porcentagem_R_falso=1-porcentagem_R_verdadeiro\n",
    "\n",
    "print('Porcentagem de Relevantes Verdadeiros: ',porcentagem_R_verdadeiro*100, \"%\")\n",
    "print('Porcentagem de Relevantes Falsos: ', porcentagem_R_falso*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = 'Verdadeiros', 'Falsos'\n",
    "I_plot = [porcentagem_I_verdadeiro, porcentagem_I_falso]\n",
    "N_plot = [porcentagem_N_verdadeiro, porcentagem_N_falso]\n",
    "R_plot = [porcentagem_R_verdadeiro, porcentagem_R_falso]\n",
    "colors = ['lightskyblue', 'lightcoral']\n",
    "explode = (0.08, 0) \n",
    "\n",
    "fig = plt.figure(figsize=(15, 5))\n",
    "plt.subplot(131)\n",
    "plt.pie(I_plot, explode=explode, labels=labels, colors=colors,\n",
    "        autopct='%1.1f%%', shadow=True, startangle=140)\n",
    "plt.axis('equal')\n",
    "plt.title(\"Porcentagem de Tweets Irrelevantes\")\n",
    "\n",
    "plt.subplot(132)\n",
    "plt.pie(N_plot, explode=explode, labels=labels, colors=colors,\n",
    "        autopct='%1.1f%%', shadow=True, startangle=140)\n",
    "plt.axis('equal')\n",
    "plt.title(\"Porcentagem de Tweets Neutros\")\n",
    "\n",
    "plt.subplot(133)\n",
    "plt.pie(R_plot, explode=explode, labels=labels, colors=colors,\n",
    "        autopct='%1.1f%%', shadow=True, startangle=140)\n",
    "plt.axis('equal')\n",
    "plt.title(\"Porcentagem de Tweets Relevantes\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Aperfeiçoamento:\n",
    "\n",
    "Os trabalhos vão evoluir em conceito dependendo da quantidade de itens avançados:\n",
    "\n",
    "- [X] Limpar: \\n, :, \", ', (, ), etc SEM remover emojis\n",
    "- [X] Corrigir separação de espaços entre palavras e emojis ou entre emojis e emojis\n",
    "- [X] Propor outras limpezas e transformações que não afetem a qualidade da informação ou classificação\n",
    "- [X] Criar categorias intermediárias de relevância baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante (3 categorias: C, mais categorias conta para B)\n",
    "- [ ] Explicar por que não posso usar o próprio classificador para gerar mais amostras de treinamento\n",
    "- [ ] Propor diferentes cenários para Naïve Bayes fora do contexto do projeto\n",
    "- [ ] Sugerir e explicar melhorias reais com indicações concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "- [X] Montar um dashboard que realiza análise de sentimento e visualiza estes dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Referências"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**\n",
    "\n",
    "[Applying Multinomial Naive Bayes to NLP Problems: A Practical Explanation](https://medium.com/syncedreview/applying-multinomial-naive-bayes-to-nlp-problems-a-practical-explanation-4f5271768ebf#:~:text=A%20solution%20would%20be%20Laplace,incorporated%20in%20every%20probability%20estimate.&text=this%20is%20a%20way%20of,it%20is%20called%20Laplace%20smoothing.) **Mais simples e Completo**\n",
    "\n",
    "[Why do we need Laplace smoothing in Naive Bayes while logarithm may resolve the problem?](https://stats.stackexchange.com/questions/274251/why-do-we-need-laplace-smoothing-in-naive-bayes-while-logarithm-may-resolve-the)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
